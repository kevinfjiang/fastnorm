# **Technical Writeup**
> buckle up


## Discussion
I will be explaining every step of the `double CUM(double Z)` algorithm line by line, and sometimes even more in-depth. For any recruiters, namely those at HFT firms, pls hit me up. I will only be discussing the original algorithm due to time constraints


### Prelims
floats abide by the IEEE754 standard where longs are just read without a complicated standard. To understand this concept I highly advise watching this [video](https://www.youtube.com/watch?v=p8u_k2LIZyo&t=715s). The logic is understanding that all floats are represented in scientific notation, 1 sign bit, 8 exponent, and 23 mantissa, first bit is always non-zero in scientific notation (so it is one, which is where the plus one comes from). Thus the value can be seen as <img src="https://render.githubusercontent.com/render/math?math=X = (1 %2B \frac{M}{2^23})*2^{E-127}">. Taking the <img src="https://render.githubusercontent.com/render/math?math=log_{2}"> allow us to rearrange a bit to get <img src="https://render.githubusercontent.com/render/math?math=log_{2}(1 %2B M) %2B E - 127">. Based on an approximation we can conclude <img src="https://render.githubusercontent.com/render/math?math=log_{2}(1 %2B M) ">

`long` performs a pseudo transformation or, the number that approximates to applying a <img src="https://render.githubusercontent.com/render/math?math=log_{2}(1 %2B M)\approx M %2B \mu"> with an error term. Thus, more rearranging gives us <img src="https://render.githubusercontent.com/render/math?math=log_{2}(x) \approx \frac{(M %2B 2^{23}*E)}{2^23} %2B \mu - 127">. <img src="https://render.githubusercontent.com/render/math?math=M %2B 2^{23}*E)"> is the bit representation of a number, thus using bit hacks to turn `float` into `long` provides an easy way to quickly take <img src="https://render.githubusercontent.com/render/math?math=log_{2}">, given it is scaled and shifted. This speed increase is the basis of this algorithim as one can greatly improve the calculations over other methods. However, with floats, one might run into `long` overflows leading to bad results, thus we apply the same logic can be applied to functions involving `double` and `long long`, just with different constants. Since I'm more familiar with the IEEE754 standard, I will be discussing `float` <> `long` but the code will demonstrate `double` <> `long long` transforrmations.


### The algorithm approximation
<p align=center><img src="https://render.githubusercontent.com/render/math?math=F(x) = \frac{e^y}{e^y%2B1}, y =0.7988x(1 %2B 0.04417x^2)" class="center"></p>

This algorithm may seem unintuitive but the algorithm is a very good approximation, likely because the derivative of <img src="https://render.githubusercontent.com/render/math?math=\frac{e^y}{e^y%2B1}"> is very similar to a normal curve. The algorithm was chosen to be the fastest because only one complex operation <img src="https://render.githubusercontent.com/render/math?math=e^x"> needed to be performed, as multiplication is trivially fast and division has gotten much faster. The main challenge is to find a function that accurately and quickly calculates <img src="https://render.githubusercontent.com/render/math?math=e^x">.

### `double CUM(double Z){` step by step
##### ```Z *= (0x127054FC55A662 + 0xD07F3F8B2FCA.2P0*(Z*Z)); ```
This step calculates <img src="https://render.githubusercontent.com/render/math?math=y"> but multiplies the values ```1.5976``` and ```0xB8AA3B295C17F``` by a constant. Our goal is to find <img src="https://render.githubusercontent.com/render/math?math=e^x">, thus in a log transformation, we multiply our value `Z` by a constant representing <img src="https://render.githubusercontent.com/render/math?math=e"> or something very similar (in this case, it is <img src="https://render.githubusercontent.com/render/math?math=e^\frac{1}{2}">, which we'll get into later). The rearranging ensures the least amount of work is done on the multiplicative end. This was determined to be the fastest order by trial and error

##### ` union { double d; long long x; } u, v;`
This step creates an anonymous struct that acts as both `long long` and `double` with bits overlapping. It is useful in a read-only context where we need to read the values as a `long` and a `double`. Using pointer casting (which if done often can be slightly slow) is undefined behavior in C and union bit hacking is defined according to some random source I read. This is useful in applying exponents. The reason we have two numbers is because we are aware that this transformation picks up some error, thus calculating <img src="https://render.githubusercontent.com/render/math?math=e^x = \frac{e^{\frac{x}{2}}}{e^{\frac{-x}{2}}}">, gets us a better approximation. ```0xB8AA3B295C17F``` actually is the `long long` representation of the bits of `double` <img src="https://render.githubusercontent.com/render/math?math=e"> divided by two or <img src="https://render.githubusercontent.com/render/math?math=e^\frac{1}{2}">

##### `u.x = (long long)( 0x3fdf127e83d16f12LL + Z );` According to the Quake3 article and trial and error, reading `double` as `long long` picks up some error, meaning we include a constant as the error minimizing term, <img src="https://render.githubusercontent.com/render/math?math=\mu">. What this number represents is a constant term added to our approximation <img src="https://render.githubusercontent.com/render/math?math=log_{2}(1%2BM)\approx M %2B \mu">.
Based on what we know of logs, we can take the exponent out and use it as multiplication, which is why we multiplied the `Z` by ```0xB8AA3B295C17F``` silently earlier. The base <img src="https://render.githubusercontent.com/render/math?math=e^\frac{1}{2}"> is a constant, thus that can be evaluated ahead of time and modified with the error term to get ```0xB8AA3B295C17F```. This represents the binary of the `double` representation of the base, but those bits read literally as a `long long`. Thus our first multiplication with the constant essentailly calculates <img src="https://render.githubusercontent.com/render/math?math=-xlog_{2}e^\frac{1}{2}">. Finally, we read the bits into our `union` to get it as both a `long long` and a `double`. Doing the computation and having the constant ahead of time prevents the need to pointer cast from our original value of a `float` to a `long` which saves a `bit` of time by going directly to a `long` to the mixed struct. We have access to the float and the long values!

##### `u.x = (long long)( 0x3fdf127e83d16f12LL - Z );` 
We repeat the same previous operation using exactly the same logic but to calculate the exponent of the base <img src="https://render.githubusercontent.com/render/math?math=e^\frac{-1}{2}">. But based on the log transformation, we can just pull the negative one out so we get <img src="https://render.githubusercontent.com/render/math?math=-xlog_{2}e^\frac{1}{2}">. Given we already computed a constant representing <img src="https://render.githubusercontent.com/render/math?math=-log_{2}e^\frac{1}{2}"> and multiplied through, we can reuse the first calculation of <img src="https://render.githubusercontent.com/render/math?math=-xlog_{2}e^\frac{1}{2}"> but negating it to get <img src="https://render.githubusercontent.com/render/math?math=-xlog_{2}e^\frac{-1}{2}">. 

##### `(u.d/v.d)` 
Giving credit where credit is due, I saw this step performed [here](https://github.com/ekmett/approximate/blob/master/cbits/fast.c). The theory is that since the approximations of <img src="https://render.githubusercontent.com/render/math?math=e^x"> have a high error, calculating <img src="https://render.githubusercontent.com/render/math?math=e^x = \frac{e^{\frac{x}{2}}}{e^{\frac{-x}{2}}}"> will reduce lots of that error because the mantissa of the numberator and denominator is the same, therefore the error is the same direction and is better approximated with this method. Thus we can concclude the above adequately represents <img src="https://render.githubusercontent.com/render/math?math=e^x">. Since below, there is another step the equivalent of <img src="https://render.githubusercontent.com/render/math?math=\frac{e^x}{e^x %2B 1}">, the error term is once again minimized by the second division

##### `return 1. - ( 1. / ((u.d/v.d) + 1.) );` 
This is the final step, find the ratio of <img src="https://render.githubusercontent.com/render/math?math=\frac{e^y}{e^y%2B1}">. This algebraic manipulation can be verified by representing the numberator as <img src="https://render.githubusercontent.com/render/math?math=e^y %2B 1 - 1">. Thus, we have an approximation of the CDF of the normal faster than any other function thanks to low-level bit manipulations. SOON I'll be explaining the crazy formula that is the FastInverseCDF. I am dreading this as I did a lot of BS to make it fast and relatively accurate. 